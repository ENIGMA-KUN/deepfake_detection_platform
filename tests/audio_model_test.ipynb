{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Detection Platform - Audio Models Test\n",
    "\n",
    "This notebook tests all audio detection models and the Acoustic Guardian Singularity Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Add the project root to the path\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Individual Audio Detector Models\n",
    "\n",
    "We'll load all the audio detector models: Wav2Vec2, XLSR+SLS, XLSR-Mamba, and TCN-Add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio detector models\n",
    "from detectors.audio_detector.wav2vec_detector import Wav2VecAudioDetector\n",
    "from detectors.audio_detector.xlsr_detector import XLSRAudioDetector\n",
    "from detectors.audio_detector.mamba_detector import MambaAudioDetector\n",
    "from detectors.audio_detector.tcn_detector import TCNAudioDetector\n",
    "\n",
    "# Initialize the audio detectors\n",
    "try:\n",
    "    print(\"Loading Wav2Vec2 model...\")\n",
    "    wav2vec_detector = Wav2VecAudioDetector(\n",
    "        model_name=\"facebook/wav2vec2-large-960h\", \n",
    "        confidence_threshold=0.5,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"Loading XLSR+SLS model...\")\n",
    "    xlsr_detector = XLSRAudioDetector(\n",
    "        model_name=\"facebook/wav2vec2-xlsr-53\", \n",
    "        confidence_threshold=0.5,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"Loading XLSR-Mamba model...\")\n",
    "    mamba_detector = MambaAudioDetector(\n",
    "        model_name=\"facebook/wav2vec2-xls-r-300m\", \n",
    "        confidence_threshold=0.5,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"Loading TCN-Add model...\")\n",
    "    tcn_detector = TCNAudioDetector(\n",
    "        model_name=\"facebook/wav2vec2-base-960h\", \n",
    "        confidence_threshold=0.5,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"All models loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Individual Models on Sample Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test audio files\n",
    "real_audio_path = os.path.join(project_root, 'tests', 'test_data', 'Real_Audio')\n",
    "fake_audio_path = os.path.join(project_root, 'tests', 'test_data', 'Fake_Audio')\n",
    "\n",
    "# List available audio files\n",
    "real_audio_files = [os.path.join(real_audio_path, f) for f in os.listdir(real_audio_path) if f.endswith(('.wav', '.mp3', '.ogg'))]\n",
    "fake_audio_files = [os.path.join(fake_audio_path, f) for f in os.listdir(fake_audio_path) if f.endswith(('.wav', '.mp3', '.ogg'))]\n",
    "\n",
    "if not real_audio_files:\n",
    "    print(\"No real audio files found\")\n",
    "else:\n",
    "    print(f\"Found {len(real_audio_files)} real audio files:\")\n",
    "    for f in real_audio_files:\n",
    "        print(f\"  {os.path.basename(f)}\")\n",
    "\n",
    "if not fake_audio_files:\n",
    "    print(\"No fake audio files found\")\n",
    "else:\n",
    "    print(f\"Found {len(fake_audio_files)} fake audio files:\")\n",
    "    for f in fake_audio_files:\n",
    "        print(f\"  {os.path.basename(f)}\")\n",
    "\n",
    "# Select test files\n",
    "real_audio_test = real_audio_files[0] if real_audio_files else None\n",
    "fake_audio_test = fake_audio_files[0] if fake_audio_files else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display audio waveform and spectrogram\n",
    "def display_audio(audio_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        librosa.display.waveshow(y, sr=sr)\n",
    "        plt.title('Waveform')\n",
    "        \n",
    "        plt.subplot(2, 1, 2)\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Spectrogram')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return y, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying audio: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display real and fake audio if available\n",
    "if real_audio_test:\n",
    "    print(f\"Real audio sample: {os.path.basename(real_audio_test)}\")\n",
    "    real_y, real_sr = display_audio(real_audio_test)\n",
    "\n",
    "if fake_audio_test:\n",
    "    print(f\"Fake audio sample: {os.path.basename(fake_audio_test)}\")\n",
    "    fake_y, fake_sr = display_audio(fake_audio_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to test models on audio files\n",
    "def test_audio_model(detector, audio_path, audio_type):\n",
    "    print(f\"Testing {detector.__class__.__name__} on {audio_type} audio...\")\n",
    "    try:\n",
    "        result = detector.detect(audio_path)\n",
    "        is_deepfake = result['is_deepfake']\n",
    "        confidence = result['confidence']\n",
    "        correct = (is_deepfake and audio_type == 'fake') or (not is_deepfake and audio_type == 'real')\n",
    "        \n",
    "        print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "        print(f\"  Confidence: {confidence:.4f}\")\n",
    "        print(f\"  Correct: {'✓' if correct else '✗'}\")\n",
    "        \n",
    "        # Display spectrogram if available\n",
    "        if 'spectrogram' in result:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.imshow(result['spectrogram'], aspect='auto', origin='lower', cmap='viridis')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f\"{detector.__class__.__name__} Spectrogram Analysis (Confidence: {confidence:.4f})\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        # Display anomaly regions if available\n",
    "        if 'anomaly_regions' in result and result['anomaly_regions']:\n",
    "            print(\"  Detected anomaly regions:\")\n",
    "            for i, region in enumerate(result['anomaly_regions']):\n",
    "                print(f\"    Region {i+1}: {region['start_time']:.2f}s - {region['end_time']:.2f}s (confidence: {region['confidence']:.4f})\")\n",
    "        \n",
    "        return result, correct\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {str(e)}\")\n",
    "        return None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test individual models if test files are available\n",
    "results = {}\n",
    "\n",
    "if real_audio_test and fake_audio_test:\n",
    "    # Test Wav2Vec2 model\n",
    "    results['wav2vec_real'] = test_audio_model(wav2vec_detector, real_audio_test, 'real')\n",
    "    results['wav2vec_fake'] = test_audio_model(wav2vec_detector, fake_audio_test, 'fake')\n",
    "    \n",
    "    # Test XLSR model\n",
    "    results['xlsr_real'] = test_audio_model(xlsr_detector, real_audio_test, 'real')\n",
    "    results['xlsr_fake'] = test_audio_model(xlsr_detector, fake_audio_test, 'fake')\n",
    "    \n",
    "    # Test Mamba model\n",
    "    results['mamba_real'] = test_audio_model(mamba_detector, real_audio_test, 'real')\n",
    "    results['mamba_fake'] = test_audio_model(mamba_detector, fake_audio_test, 'fake')\n",
    "    \n",
    "    # Test TCN model\n",
    "    results['tcn_real'] = test_audio_model(tcn_detector, real_audio_test, 'real')\n",
    "    results['tcn_fake'] = test_audio_model(tcn_detector, fake_audio_test, 'fake')\n",
    "else:\n",
    "    print(\"Cannot test models without both real and fake audio samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Audio Ensemble Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the audio ensemble detector\n",
    "from detectors.audio_detector.ensemble import AudioEnsembleDetector\n",
    "\n",
    "# Create the ensemble detector with all individual detectors\n",
    "if 'wav2vec_detector' in locals() and 'xlsr_detector' in locals() and 'mamba_detector' in locals() and 'tcn_detector' in locals():\n",
    "    detectors = [wav2vec_detector, xlsr_detector, mamba_detector, tcn_detector]\n",
    "    audio_ensemble = AudioEnsembleDetector(\n",
    "        detectors=detectors,\n",
    "        weights=None,  # Use equal weights initially\n",
    "        threshold=0.5,\n",
    "        enable_singularity=False  # First test without Singularity Mode\n",
    "    )\n",
    "    \n",
    "    print(f\"Created Audio Ensemble Detector with {len(detectors)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ensemble on real and fake audio\n",
    "if 'audio_ensemble' in locals() and real_audio_test and fake_audio_test:\n",
    "    # Test on real audio\n",
    "    print(\"Testing Audio Ensemble on real audio...\")\n",
    "    ensemble_real_result = audio_ensemble.predict(real_audio_test)\n",
    "    is_deepfake = ensemble_real_result['is_deepfake']\n",
    "    confidence = ensemble_real_result['confidence']\n",
    "    print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "    print(f\"  Confidence: {confidence:.4f}\")\n",
    "    print(f\"  Correct: {'✓' if not is_deepfake else '✗'}\")\n",
    "    \n",
    "    # Show individual model contributions\n",
    "    if 'individual_results' in ensemble_real_result:\n",
    "        print(\"\\nIndividual model contributions:\")\n",
    "        for result in ensemble_real_result['individual_results']:\n",
    "            model_name = result['model']\n",
    "            confidence = result['confidence']\n",
    "            weight = result['weight']\n",
    "            print(f\"  {model_name}: Confidence = {confidence:.4f}, Weight = {weight:.2f}\")\n",
    "    \n",
    "    # Test on fake audio\n",
    "    print(\"\\nTesting Audio Ensemble on fake audio...\")\n",
    "    ensemble_fake_result = audio_ensemble.predict(fake_audio_test)\n",
    "    is_deepfake = ensemble_fake_result['is_deepfake']\n",
    "    confidence = ensemble_fake_result['confidence']\n",
    "    print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "    print(f\"  Confidence: {confidence:.4f}\")\n",
    "    print(f\"  Correct: {'✓' if is_deepfake else '✗'}\")\n",
    "    \n",
    "    # Show individual model contributions\n",
    "    if 'individual_results' in ensemble_fake_result:\n",
    "        print(\"\\nIndividual model contributions:\")\n",
    "        for result in ensemble_fake_result['individual_results']:\n",
    "            model_name = result['model']\n",
    "            confidence = result['confidence']\n",
    "            weight = result['weight']\n",
    "            print(f\"  {model_name}: Confidence = {confidence:.4f}, Weight = {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Acoustic Guardian Singularity Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Singularity Mode in the ensemble detector\n",
    "if 'detectors' in locals():\n",
    "    audio_ensemble_with_singularity = AudioEnsembleDetector(\n",
    "        detectors=detectors,\n",
    "        weights=None,\n",
    "        threshold=0.5,\n",
    "        enable_singularity=True  # Enable Singularity Mode\n",
    "    )\n",
    "    \n",
    "    print(\"Created Audio Ensemble Detector with Acoustic Guardian Singularity Mode enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Singularity Mode on real and fake audio\n",
    "if 'audio_ensemble_with_singularity' in locals() and real_audio_test and fake_audio_test:\n",
    "    # Test on real audio\n",
    "    print(\"Testing Acoustic Guardian on real audio...\")\n",
    "    try:\n",
    "        singularity_real_result = audio_ensemble_with_singularity.predict(real_audio_test)\n",
    "        is_deepfake = singularity_real_result['is_deepfake']\n",
    "        confidence = singularity_real_result['confidence']\n",
    "        print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "        print(f\"  Confidence: {confidence:.4f}\")\n",
    "        print(f\"  Correct: {'✓' if not is_deepfake else '✗'}\")\n",
    "        \n",
    "        # Show Singularity Mode information\n",
    "        if 'singularity_mode' in singularity_real_result:\n",
    "            sm_info = singularity_real_result['singularity_mode']\n",
    "            print(\"\\nSingularity Mode information:\")\n",
    "            for key, value in sm_info.items():\n",
    "                if key != 'adaptive_weights':\n",
    "                    print(f\"  {key}: {value}\")\n",
    "        \n",
    "        # Display enhanced spectrogram if available\n",
    "        if 'spectrogram' in singularity_real_result:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.imshow(singularity_real_result['spectrogram'], aspect='auto', origin='lower', cmap='viridis')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f\"Acoustic Guardian Enhanced Spectrogram (Real Audio)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing Acoustic Guardian on real audio: {str(e)}\")\n",
    "    \n",
    "    # Test on fake audio\n",
    "    print(\"\\nTesting Acoustic Guardian on fake audio...\")\n",
    "    try:\n",
    "        singularity_fake_result = audio_ensemble_with_singularity.predict(fake_audio_test)\n",
    "        is_deepfake = singularity_fake_result['is_deepfake']\n",
    "        confidence = singularity_fake_result['confidence']\n",
    "        print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "        print(f\"  Confidence: {confidence:.4f}\")\n",
    "        print(f\"  Correct: {'✓' if is_deepfake else '✗'}\")\n",
    "        \n",
    "        # Show Singularity Mode information\n",
    "        if 'singularity_mode' in singularity_fake_result:\n",
    "            sm_info = singularity_fake_result['singularity_mode']\n",
    "            print(\"\\nSingularity Mode information:\")\n",
    "            for key, value in sm_info.items():\n",
    "                if key != 'adaptive_weights':\n",
    "                    print(f\"  {key}: {value}\")\n",
    "        \n",
    "        # Display enhanced spectrogram if available\n",
    "        if 'spectrogram' in singularity_fake_result:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.imshow(singularity_fake_result['spectrogram'], aspect='auto', origin='lower', cmap='viridis')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f\"Acoustic Guardian Enhanced Spectrogram (Fake Audio)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing Acoustic Guardian on fake audio: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance across models\n",
    "if all(var in locals() for var in ['ensemble_real_result', 'ensemble_fake_result', 'singularity_real_result', 'singularity_fake_result']):\n",
    "    # Collect model performances\n",
    "    models = []\n",
    "    real_confidences = []\n",
    "    fake_confidences = []\n",
    "    \n",
    "    # Add individual model results\n",
    "    for model_name in ['wav2vec', 'xlsr', 'mamba', 'tcn']:\n",
    "        real_key = f\"{model_name}_real\"\n",
    "        fake_key = f\"{model_name}_fake\"\n",
    "        \n",
    "        if real_key in results and fake_key in results:\n",
    "            real_result, _ = results[real_key]\n",
    "            fake_result, _ = results[fake_key]\n",
    "            \n",
    "            if real_result and fake_result:\n",
    "                models.append(model_name.capitalize())\n",
    "                real_confidences.append(real_result['confidence'])\n",
    "                fake_confidences.append(fake_result['confidence'])\n",
    "    \n",
    "    # Add ensemble results\n",
    "    models.append('Ensemble')\n",
    "    real_confidences.append(ensemble_real_result['confidence'])\n",
    "    fake_confidences.append(ensemble_fake_result['confidence'])\n",
    "    \n",
    "    # Add Singularity Mode results\n",
    "    models.append('Acoustic Guardian')\n",
    "    real_confidences.append(singularity_real_result['confidence'])\n",
    "    fake_confidences.append(singularity_fake_result['confidence'])\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Real audio (lower confidence is better)\n",
    "    ax1.bar(models, real_confidences)\n",
    "    ax1.set_title('Real Audio Detection Confidence')\n",
    "    ax1.set_ylabel('Confidence (lower is better for real)')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.axhline(y=0.5, color='r', linestyle='--')\n",
    "    plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Fake audio (higher confidence is better)\n",
    "    ax2.bar(models, fake_confidences)\n",
    "    ax2.set_title('Fake Audio Detection Confidence')\n",
    "    ax2.set_ylabel('Confidence (higher is better for fake)')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.axhline(y=0.5, color='r', linestyle='--')\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance improvements\n",
    "if all(var in locals() for var in ['ensemble_real_result', 'ensemble_fake_result', 'singularity_real_result', 'singularity_fake_result']):\n",
    "    # For real audio (lower confidence is better)\n",
    "    real_ensemble_conf = ensemble_real_result['confidence']\n",
    "    real_singularity_conf = singularity_real_result['confidence']\n",
    "    real_improvement = max(0, real_ensemble_conf - real_singularity_conf)\n",
    "    \n",
    "    # For fake audio (higher confidence is better)\n",
    "    fake_ensemble_conf = ensemble_fake_result['confidence']\n",
    "    fake_singularity_conf = singularity_fake_result['confidence']\n",
    "    fake_improvement = max(0, fake_singularity_conf - fake_ensemble_conf)\n",
    "    \n",
    "    print(\"Performance Summary:\")\n",
    "    print(f\"Acoustic Guardian improvement on real audio: {real_improvement:.4f} reduction in confidence\")\n",
    "    print(f\"Acoustic Guardian improvement on fake audio: {fake_improvement:.4f} increase in confidence\")\n",
    "    print(f\"Overall improvement: {(real_improvement + fake_improvement) / 2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
