{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Detection Platform - Video Models Test\n",
    "\n",
    "This notebook tests all video detection models and the Temporal Sentinel Singularity Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from IPython.display import Video, display\n",
    "\n",
    "# Add the project root to the path\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Individual Video Detector Models\n",
    "\n",
    "We'll load all the video detector models: GenConvit, TimeSformer, SlowFast, Video Swin, and X3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'av'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import video detector models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo_detector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenconvit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenConvitVideoDetector\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo_detector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimesformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSformerVideoDetector\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo_detector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslowfast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SlowFastVideoDetector\n",
      "File \u001b[1;32mc:\\Users\\chakr\\Documents\\GitHub\\deepfake_detection_platform\\detectors\\video_detector\\genconvit.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Any, List, Optional, Tuple\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mav\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViTImageProcessor, ViTForImageClassification\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'av'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import video detector models\n",
    "from detectors.video_detector.genconvit import GenConvitVideoDetector\n",
    "from detectors.video_detector.timesformer import TimeSformerVideoDetector\n",
    "from detectors.video_detector.slowfast import SlowFastVideoDetector\n",
    "from detectors.video_detector.video_swin import VideoSwinDetector\n",
    "from detectors.video_detector.x3d import X3DVideoDetector\n",
    "\n",
    "# Define the device to use\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the video detectors\n",
    "try:\n",
    "    print(\"Loading GenConvit model...\")\n",
    "    genconvit_detector = GenConvitVideoDetector(model_name=\"facebook/genconvit-base\", \n",
    "                                     confidence_threshold=0.5,\n",
    "                                     device=device)\n",
    "    \n",
    "    print(\"Loading TimeSformer model...\")\n",
    "    timesformer_detector = TimeSformerVideoDetector(model_name=\"facebook/timesformer-base-224\", \n",
    "                                     confidence_threshold=0.5,\n",
    "                                     device=device)\n",
    "    \n",
    "    print(\"Loading SlowFast model...\")\n",
    "    slowfast_detector = SlowFastVideoDetector(model_name=\"facebook/slowfast-r50\", \n",
    "                                   confidence_threshold=0.5,\n",
    "                                   device=device)\n",
    "    \n",
    "    print(\"Loading Video Swin model...\")\n",
    "    video_swin_detector = VideoSwinDetector(model_name=\"microsoft/swin-tiny-video\", \n",
    "                                   confidence_threshold=0.5,\n",
    "                                   device=device)\n",
    "    \n",
    "    print(\"Loading X3D model...\")\n",
    "    x3d_detector = X3DVideoDetector(model_name=\"facebook/x3d-m\", \n",
    "                          confidence_threshold=0.5,\n",
    "                          device=device)\n",
    "    \n",
    "    print(\"All models loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Individual Models on Sample Videos\n",
    "\n",
    "We'll test each model on sample real and fake videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test videos\n",
    "real_video_path = os.path.join(project_root, 'tests', 'test_data', 'Real_Video', 'real_video_sample.mp4')\n",
    "fake_video_path = os.path.join(project_root, 'tests', 'test_data', 'Fake_Video', 'fake_video_sample.mp4')\n",
    "\n",
    "# Check if videos exist\n",
    "if not os.path.exists(real_video_path):\n",
    "    raise FileNotFoundError(f\"Real video not found: {real_video_path}\")\n",
    "if not os.path.exists(fake_video_path):\n",
    "    raise FileNotFoundError(f\"Fake video not found: {fake_video_path}\")\n",
    "\n",
    "# Display the test videos\n",
    "print(\"Real Video:\")\n",
    "display(Video(real_video_path, width=320))\n",
    "print(\"\\nFake Video:\")\n",
    "display(Video(fake_video_path, width=320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to test models on videos\n",
    "def test_video_model(detector, video_path, video_type):\n",
    "    print(f\"Testing {detector.__class__.__name__} on {video_type} video...\")\n",
    "    try:\n",
    "        result = detector.detect(video_path)\n",
    "        is_deepfake = result['is_deepfake']\n",
    "        confidence = result['confidence']\n",
    "        correct = (is_deepfake and video_type == 'fake') or (not is_deepfake and video_type == 'real')\n",
    "        \n",
    "        print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "        print(f\"  Confidence: {confidence:.4f}\")\n",
    "        print(f\"  Correct: {'✓' if correct else '✗'}\")\n",
    "        \n",
    "        # Display temporal heatmap if available\n",
    "        if 'temporal_heatmap' in result:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(result['temporal_heatmap'])\n",
    "            plt.title(f\"Temporal Heatmap for {video_type} Video\")\n",
    "            plt.xlabel(\"Frame Index\")\n",
    "            plt.ylabel(\"Deepfake Probability\")\n",
    "            plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return result, correct\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {str(e)}\")\n",
    "        return None, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414e1af",
   "metadata": {},
   "source": [
    "## Part 2: Test all individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Test all individual models\n",
    "\n",
    "# Test GenConvit model\n",
    "genconvit_real_result, genconvit_real_correct = test_video_model(genconvit_detector, real_video_path, 'real')\n",
    "genconvit_fake_result, genconvit_fake_correct = test_video_model(genconvit_detector, fake_video_path, 'fake')\n",
    "\n",
    "# Test TimeSformer model\n",
    "timesformer_real_result, timesformer_real_correct = test_video_model(timesformer_detector, real_video_path, 'real')\n",
    "timesformer_fake_result, timesformer_fake_correct = test_video_model(timesformer_detector, fake_video_path, 'fake')\n",
    "\n",
    "# Test SlowFast model\n",
    "slowfast_real_result, slowfast_real_correct = test_video_model(slowfast_detector, real_video_path, 'real')\n",
    "slowfast_fake_result, slowfast_fake_correct = test_video_model(slowfast_detector, fake_video_path, 'fake')\n",
    "\n",
    "# Test Video Swin model\n",
    "video_swin_real_result, video_swin_real_correct = test_video_model(video_swin_detector, real_video_path, 'real')\n",
    "video_swin_fake_result, video_swin_fake_correct = test_video_model(video_swin_detector, fake_video_path, 'fake')\n",
    "\n",
    "# Test X3D model\n",
    "x3d_real_result, x3d_real_correct = test_video_model(x3d_detector, real_video_path, 'real')\n",
    "x3d_fake_result, x3d_fake_correct = test_video_model(x3d_detector, fake_video_path, 'fake')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e0330",
   "metadata": {},
   "source": [
    "## Part 3: Test Video Ensemble Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78bf138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Test Video Ensemble Detector\n",
    "\n",
    "# Import the video ensemble detector\n",
    "from detectors.video_detector.ensemble import VideoEnsembleDetector\n",
    "\n",
    "# Create the ensemble detector with all individual detectors\n",
    "detectors = [genconvit_detector, timesformer_detector, slowfast_detector, video_swin_detector, x3d_detector]\n",
    "video_ensemble = VideoEnsembleDetector(\n",
    "    detectors=detectors,\n",
    "    weights=None,  # Use equal weights initially\n",
    "    threshold=0.5,\n",
    "    enable_singularity=False  # First test without Singularity Mode\n",
    ")\n",
    "\n",
    "print(f\"Created Video Ensemble Detector with {len(detectors)} models\")\n",
    "\n",
    "# Test ensemble on real video\n",
    "print(\"Testing Video Ensemble on real video...\")\n",
    "ensemble_real_result = video_ensemble.predict(real_video_path)\n",
    "is_deepfake = ensemble_real_result['is_deepfake']\n",
    "confidence = ensemble_real_result['confidence']\n",
    "print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "print(f\"  Confidence: {confidence:.4f}\")\n",
    "print(f\"  Correct: {'✓' if not is_deepfake else '✗'}\")\n",
    "\n",
    "# Show individual model contributions if available\n",
    "if 'individual_results' in ensemble_real_result:\n",
    "    print(\"\\nIndividual model contributions:\")\n",
    "    for result in ensemble_real_result['individual_results']:\n",
    "        model_name = result['model']\n",
    "        confidence = result['confidence']\n",
    "        weight = result['weight']\n",
    "        print(f\"  {model_name}: Confidence = {confidence:.4f}, Weight = {weight:.2f}\")\n",
    "\n",
    "# Test ensemble on fake video\n",
    "print(\"Testing Video Ensemble on fake video...\")\n",
    "ensemble_fake_result = video_ensemble.predict(fake_video_path)\n",
    "is_deepfake = ensemble_fake_result['is_deepfake']\n",
    "confidence = ensemble_fake_result['confidence']\n",
    "print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "print(f\"  Confidence: {confidence:.4f}\")\n",
    "print(f\"  Correct: {'✓' if is_deepfake else '✗'}\")\n",
    "\n",
    "# Show individual model contributions if available\n",
    "if 'individual_results' in ensemble_fake_result:\n",
    "    print(\"\\nIndividual model contributions:\")\n",
    "    for result in ensemble_fake_result['individual_results']:\n",
    "        model_name = result['model']\n",
    "        confidence = result['confidence']\n",
    "        weight = result['weight']\n",
    "        print(f\"  {model_name}: Confidence = {confidence:.4f}, Weight = {weight:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca56061",
   "metadata": {},
   "source": [
    "## Part 4: Test Temporal Sentinel Singularity Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e400d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Test Temporal Sentinel Singularity Mode\n",
    "\n",
    "# Enable Singularity Mode in the ensemble detector\n",
    "video_ensemble_with_singularity = VideoEnsembleDetector(\n",
    "    detectors=detectors,\n",
    "    weights=None,\n",
    "    threshold=0.5,\n",
    "    enable_singularity=True  # Enable Singularity Mode\n",
    ")\n",
    "\n",
    "print(\"Created Video Ensemble Detector with Temporal Sentinel Singularity Mode enabled\")\n",
    "\n",
    "# Test Singularity Mode on real video\n",
    "print(\"Testing Temporal Sentinel on real video...\")\n",
    "try:\n",
    "    singularity_real_result = video_ensemble_with_singularity.predict(real_video_path)\n",
    "    is_deepfake = singularity_real_result['is_deepfake']\n",
    "    confidence = singularity_real_result['confidence']\n",
    "    print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "    print(f\"  Confidence: {confidence:.4f}\")\n",
    "    print(f\"  Correct: {'✓' if not is_deepfake else '✗'}\")\n",
    "    \n",
    "    # Show Singularity Mode information if available\n",
    "    if 'singularity_mode' in singularity_real_result:\n",
    "        sm_info = singularity_real_result['singularity_mode']\n",
    "        print(\"\\nSingularity Mode information:\")\n",
    "        for key, value in sm_info.items():\n",
    "            if key != 'adaptive_weights':  # Weights would be too verbose\n",
    "                print(f\"  {key}: {value}\")\n",
    "        \n",
    "        if 'adaptive_weights' in sm_info:\n",
    "            print(\"  Adaptive weights:\")\n",
    "            for model, weight in sm_info['adaptive_weights'].items():\n",
    "                print(f\"    {model}: {weight:.4f}\")\n",
    "                \n",
    "    # Display temporal consistency plot if available\n",
    "    if 'temporal_consistency' in singularity_real_result:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.plot(singularity_real_result['temporal_consistency'])\n",
    "        plt.title(\"Temporal Consistency for Real Video\")\n",
    "        plt.xlabel(\"Frame Pairs\")\n",
    "        plt.ylabel(\"Consistency Score\")\n",
    "        plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error testing Temporal Sentinel: {str(e)}\")\n",
    "\n",
    "# Test Singularity Mode on fake video\n",
    "print(\"Testing Temporal Sentinel on fake video...\")\n",
    "try:\n",
    "    singularity_fake_result = video_ensemble_with_singularity.predict(fake_video_path)\n",
    "    is_deepfake = singularity_fake_result['is_deepfake']\n",
    "    confidence = singularity_fake_result['confidence']\n",
    "    print(f\"  Prediction: {'Deepfake' if is_deepfake else 'Real'}\")\n",
    "    print(f\"  Confidence: {confidence:.4f}\")\n",
    "    print(f\"  Correct: {'✓' if is_deepfake else '✗'}\")\n",
    "    \n",
    "    # Show Singularity Mode information if available\n",
    "    if 'singularity_mode' in singularity_fake_result:\n",
    "        sm_info = singularity_fake_result['singularity_mode']\n",
    "        print(\"\\nSingularity Mode information:\")\n",
    "        for key, value in sm_info.items():\n",
    "            if key != 'adaptive_weights':  # Weights would be too verbose\n",
    "                print(f\"  {key}: {value}\")\n",
    "        \n",
    "        if 'adaptive_weights' in sm_info:\n",
    "            print(\"  Adaptive weights:\")\n",
    "            for model, weight in sm_info['adaptive_weights'].items():\n",
    "                print(f\"    {model}: {weight:.4f}\")\n",
    "                \n",
    "    # Display temporal consistency plot if available\n",
    "    if 'temporal_consistency' in singularity_fake_result:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.plot(singularity_fake_result['temporal_consistency'])\n",
    "        plt.title(\"Temporal Consistency for Fake Video\")\n",
    "        plt.xlabel(\"Frame Pairs\")\n",
    "        plt.ylabel(\"Consistency Score\")\n",
    "        plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error testing Temporal Sentinel: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5faadd",
   "metadata": {},
   "source": [
    "## Part 5: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Performance Comparison\n",
    "\n",
    "# Collect all confidence scores\n",
    "real_video_confidences = {\n",
    "    'GenConvit': genconvit_real_result['confidence'] if genconvit_real_result else 0,\n",
    "    'TimeSformer': timesformer_real_result['confidence'] if timesformer_real_result else 0,\n",
    "    'SlowFast': slowfast_real_result['confidence'] if slowfast_real_result else 0,\n",
    "    'Video Swin': video_swin_real_result['confidence'] if video_swin_real_result else 0,\n",
    "    'X3D': x3d_real_result['confidence'] if x3d_real_result else 0,\n",
    "    'Ensemble': ensemble_real_result['confidence'],\n",
    "    'Temporal Sentinel': singularity_real_result['confidence']\n",
    "}\n",
    "\n",
    "fake_video_confidences = {\n",
    "    'GenConvit': genconvit_fake_result['confidence'] if genconvit_fake_result else 0,\n",
    "    'TimeSformer': timesformer_fake_result['confidence'] if timesformer_fake_result else 0,\n",
    "    'SlowFast': slowfast_fake_result['confidence'] if slowfast_fake_result else 0,\n",
    "    'Video Swin': video_swin_fake_result['confidence'] if video_swin_fake_result else 0,\n",
    "    'X3D': x3d_fake_result['confidence'] if x3d_fake_result else 0,\n",
    "    'Ensemble': ensemble_fake_result['confidence'],\n",
    "    'Temporal Sentinel': singularity_fake_result['confidence']\n",
    "}\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Real video confidences\n",
    "models = list(real_video_confidences.keys())\n",
    "confidences = list(real_video_confidences.values())\n",
    "axes[0].bar(models, confidences, color=['blue', 'blue', 'blue', 'blue', 'blue', 'green', 'red'])\n",
    "axes[0].set_title('Real Video Confidence Scores')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Confidence (lower is better for real)')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].axhline(y=0.5, color='r', linestyle='--')\n",
    "axes[0].set_xticklabels(models, rotation=45)\n",
    "\n",
    "# Fake video confidences\n",
    "models = list(fake_video_confidences.keys())\n",
    "confidences = list(fake_video_confidences.values())\n",
    "axes[1].bar(models, confidences, color=['blue', 'blue', 'blue', 'blue', 'blue', 'green', 'red'])\n",
    "axes[1].set_title('Fake Video Confidence Scores')\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('Confidence (higher is better for fake)')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].axhline(y=0.5, color='r', linestyle='--')\n",
    "axes[1].set_xticklabels(models, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be088817",
   "metadata": {},
   "source": [
    "## Part 6: Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6: Conclusion\n",
    "\n",
    "# Calculate accuracy and improvement\n",
    "# For real video (lower confidence is better)\n",
    "real_video_improvement = max(0, np.mean([v for k, v in real_video_confidences.items() if k not in ['Ensemble', 'Temporal Sentinel']]) - real_video_confidences['Temporal Sentinel'])\n",
    "\n",
    "# For fake video (higher confidence is better)\n",
    "fake_video_improvement = max(0, fake_video_confidences['Temporal Sentinel'] - np.mean([v for k, v in fake_video_confidences.items() if k not in ['Ensemble', 'Temporal Sentinel']]))\n",
    "\n",
    "print(\"Test Results Summary:\")\n",
    "print(f\"Temporal Sentinel performance improvement on real video: {real_video_improvement:.4f} (lower confidence is better)\")\n",
    "print(f\"Temporal Sentinel performance improvement on fake video: {fake_video_improvement:.4f} (higher confidence is better)\")\n",
    "print(f\"Average improvement: {(real_video_improvement + fake_video_improvement) / 2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b7671",
   "metadata": {},
   "source": [
    "## Part 7: Frame-by-Frame Analysis with Singularity Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a499f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 7: Frame-by-Frame Analysis with Singularity Mode\n",
    "\n",
    "# This section shows how the Temporal Sentinel analyzes individual frames\n",
    "# and tracks inconsistencies across the video\n",
    "\n",
    "from detectors.video_detector.frame_analyzer import VideoFrameAnalyzer\n",
    "import cv2\n",
    "\n",
    "# Create a frame analyzer\n",
    "frame_analyzer = VideoFrameAnalyzer()\n",
    "\n",
    "def analyze_video_frames(video_path, is_fake=False):\n",
    "    \"\"\"Perform frame-by-frame analysis on a video file\"\"\"\n",
    "    # Extract some frames from the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    print(f\"Analyzing video: {video_path}\")\n",
    "    print(f\"Total frames: {total_frames}, FPS: {fps:.2f}\")\n",
    "    \n",
    "    # Sample frames at regular intervals\n",
    "    sample_count = min(8, total_frames)\n",
    "    frame_indices = [int(i * total_frames / sample_count) for i in range(sample_count)]\n",
    "    \n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append((idx, frame))\n",
    "    cap.release()\n",
    "    \n",
    "    # Display sampled frames\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (idx, frame) in enumerate(frames):\n",
    "        if i < len(axes):\n",
    "            axes[i].imshow(frame)\n",
    "            axes[i].set_title(f\"Frame {idx}\")\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"{'Fake' if is_fake else 'Real'} Video - Sample Frames\")\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "    \n",
    "    # Run frame analysis with the Singularity Mode\n",
    "    results = []\n",
    "    for idx, frame in frames:\n",
    "        # Convert frame to format expected by the analyzer\n",
    "        analysis = frame_analyzer.analyze_frame(frame)\n",
    "        results.append((idx, analysis))\n",
    "    \n",
    "    # Plot deepfake probability for each frame\n",
    "    frame_indices = [idx for idx, _ in results]\n",
    "    probabilities = [result['deepfake_probability'] for _, result in results]\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(frame_indices, probabilities, 'o-', linewidth=2)\n",
    "    plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "    plt.title(f\"{'Fake' if is_fake else 'Real'} Video - Frame-by-Frame Deepfake Probability\")\n",
    "    plt.xlabel(\"Frame Index\")\n",
    "    plt.ylabel(\"Deepfake Probability\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return frames, results\n",
    "\n",
    "# Analyze real video\n",
    "real_frames, real_analysis = analyze_video_frames(real_video_path, is_fake=False)\n",
    "\n",
    "# Analyze fake video\n",
    "fake_frames, fake_analysis = analyze_video_frames(fake_video_path, is_fake=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69767c54",
   "metadata": {},
   "source": [
    "## Part 8: Temporal Consistency Analysis with Singularity Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0efb33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 8: Temporal Consistency Analysis with Singularity Mode\n",
    "\n",
    "# Analyze temporal consistency between consecutive frames\n",
    "from app.core.singularity_manager import SingularityManager\n",
    "\n",
    "# Create a Singularity Manager for advanced analysis\n",
    "singularity_manager = SingularityManager()\n",
    "\n",
    "def analyze_temporal_consistency(video_path, is_fake=False):\n",
    "    \"\"\"Analyze the temporal consistency of a video using the Singularity Manager\"\"\"\n",
    "    print(f\"\\nAnalyzing temporal consistency for {'fake' if is_fake else 'real'} video...\")\n",
    "    \n",
    "    try:\n",
    "        # Run the full singularity analysis\n",
    "        analysis_result = singularity_manager.analyze_video(\n",
    "            video_path, \n",
    "            deepfake_type=\"all\",\n",
    "            detailed_analysis=True\n",
    "        )\n",
    "        \n",
    "        # Extract consistency metrics\n",
    "        consistency_score = analysis_result.get('temporal_consistency_score', 0)\n",
    "        frame_consistency = analysis_result.get('frame_consistency', [])\n",
    "        anomalies = analysis_result.get('detected_anomalies', [])\n",
    "        \n",
    "        print(f\"Overall temporal consistency score: {consistency_score:.4f}\")\n",
    "        print(f\"Number of detected anomalies: {len(anomalies)}\")\n",
    "        \n",
    "        if frame_consistency and len(frame_consistency) > 1:\n",
    "            # Plot the frame consistency\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            plt.plot(frame_consistency, linewidth=2)\n",
    "            plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "            plt.title(f\"{'Fake' if is_fake else 'Real'} Video - Frame Consistency\")\n",
    "            plt.xlabel(\"Frame Pair Index\")\n",
    "            plt.ylabel(\"Consistency Score\")\n",
    "            plt.ylim(0, 1)\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        \n",
    "        # If there are anomalies and frames available, show examples\n",
    "        if anomalies and 'anomaly_frames' in analysis_result:\n",
    "            anomaly_frames = analysis_result['anomaly_frames']\n",
    "            if anomaly_frames:\n",
    "                num_frames = min(4, len(anomaly_frames))\n",
    "                fig, axes = plt.subplots(1, num_frames, figsize=(16, 5))\n",
    "                \n",
    "                if num_frames == 1:\n",
    "                    axes = [axes]\n",
    "                \n",
    "                for i in range(num_frames):\n",
    "                    frame = anomaly_frames[i]['frame']\n",
    "                    frame_idx = anomaly_frames[i]['frame_idx']\n",
    "                    score = anomaly_frames[i]['anomaly_score']\n",
    "                    \n",
    "                    axes[i].imshow(frame)\n",
    "                    axes[i].set_title(f\"Frame {frame_idx}\\nAnomaly: {score:.4f}\")\n",
    "                    axes[i].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.suptitle(f\"Detected Anomalies in {'Fake' if is_fake else 'Real'} Video\")\n",
    "                plt.subplots_adjust(top=0.85)\n",
    "                plt.show()\n",
    "        \n",
    "        return analysis_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in temporal consistency analysis: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Analyze real video temporal consistency\n",
    "real_temporal_analysis = analyze_temporal_consistency(real_video_path, is_fake=False)\n",
    "\n",
    "# Analyze fake video temporal consistency\n",
    "fake_temporal_analysis = analyze_temporal_consistency(fake_video_path, is_fake=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4776ea07",
   "metadata": {},
   "source": [
    "## Part 9: Final Evaluation and Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 9: Final Evaluation and Comparative Analysis\n",
    "\n",
    "# Compare the effectiveness of standard ensemble vs. Singularity Mode\n",
    "print(\"\\n== Final Deepfake Detection Evaluation ==\\n\")\n",
    "\n",
    "# Function to evaluate accuracy\n",
    "def evaluate_detection(real_result, fake_result):\n",
    "    # Real should be classified as not deepfake\n",
    "    real_correct = not real_result['is_deepfake'] if real_result else False\n",
    "    # Fake should be classified as deepfake\n",
    "    fake_correct = fake_result['is_deepfake'] if fake_result else False\n",
    "    \n",
    "    accuracy = ((1 if real_correct else 0) + (1 if fake_correct else 0)) / 2\n",
    "    return accuracy, real_correct, fake_correct\n",
    "\n",
    "# Standard individual models\n",
    "model_results = [\n",
    "    (\"GenConvit\", evaluate_detection(genconvit_real_result, genconvit_fake_result)),\n",
    "    (\"TimeSformer\", evaluate_detection(timesformer_real_result, timesformer_fake_result)),\n",
    "    (\"SlowFast\", evaluate_detection(slowfast_real_result, slowfast_fake_result)),\n",
    "    (\"Video Swin\", evaluate_detection(video_swin_real_result, video_swin_fake_result)),\n",
    "    (\"X3D\", evaluate_detection(x3d_real_result, x3d_fake_result))\n",
    "]\n",
    "\n",
    "# Ensemble and Singularity\n",
    "ensemble_acc = evaluate_detection(ensemble_real_result, ensemble_fake_result)\n",
    "singularity_acc = evaluate_detection(singularity_real_result, singularity_fake_result)\n",
    "\n",
    "# Print results\n",
    "print(\"Individual Model Accuracy:\")\n",
    "for model_name, (acc, real_correct, fake_correct) in model_results:\n",
    "    print(f\"  {model_name}: {acc:.4f} (Real: {'✓' if real_correct else '✗'}, Fake: {'✓' if fake_correct else '✗'})\")\n",
    "\n",
    "print(f\"\\nStandard Ensemble Accuracy: {ensemble_acc[0]:.4f} (Real: {'✓' if ensemble_acc[1] else '✗'}, Fake: {'✓' if ensemble_acc[2] else '✗'})\")\n",
    "print(f\"Temporal Sentinel Accuracy: {singularity_acc[0]:.4f} (Real: {'✓' if singularity_acc[1] else '✗'}, Fake: {'✓' if singularity_acc[2] else '✗'})\")\n",
    "\n",
    "# Calculate improvement\n",
    "avg_individual_acc = sum(acc for _, (acc, _, _) in model_results) / len(model_results)\n",
    "improvement_over_individual = singularity_acc[0] - avg_individual_acc\n",
    "improvement_over_ensemble = singularity_acc[0] - ensemble_acc[0]\n",
    "\n",
    "print(f\"\\nTemporal Sentinel improvement over individual models: {improvement_over_individual:.4f}\")\n",
    "print(f\"Temporal Sentinel improvement over standard ensemble: {improvement_over_ensemble:.4f}\")\n",
    "\n",
    "# Plot comparative analysis\n",
    "models = [name for name, _ in model_results] + [\"Ensemble\", \"Temporal Sentinel\"]\n",
    "accuracies = [acc for _, (acc, _, _) in model_results] + [ensemble_acc[0], singularity_acc[0]]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(models, accuracies, color=['blue', 'blue', 'blue', 'blue', 'blue', 'green', 'red'])\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)  # Random guess line\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add a legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='blue', label='Individual Models'),\n",
    "    Patch(facecolor='green', label='Standard Ensemble'),\n",
    "    Patch(facecolor='red', label='Temporal Sentinel')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper left')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThis test notebook demonstrates the effectiveness of combining multiple video-based deepfake detection models\")\n",
    "print(\"with the Temporal Sentinel Singularity Mode, which provides improved accuracy and detailed temporal analysis.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
